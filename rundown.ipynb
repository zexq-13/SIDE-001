{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ae2c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Documents in Loader\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "def load_from_txt(filepath):\n",
    "    loader=TextLoader(filepath,encoding='utf-8')\n",
    "    return loader.load()\n",
    "info=load_from_txt('./Dataset/Data.txt') # Change to path of Data file\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbfce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Documents into chunks\n",
    "\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "\n",
    "default_headers= [\n",
    "    (\"#\", \"Heading\"),\n",
    "    (\"##\", \"Subheading\"),\n",
    "    (\"###\", \"Question\"),\n",
    "]\n",
    "\n",
    "def markdown_split(data,headers_split=default_headers):\n",
    "    markdown_splitter=MarkdownHeaderTextSplitter(\n",
    "        headers_to_split_on=headers_split\n",
    "    )\n",
    "    md_header_splits=markdown_splitter.split_text(data)\n",
    "    return md_header_splits\n",
    "\n",
    "md_split=markdown_split(info[0].page_content)\n",
    "md_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1d3469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting OpenAI embeddings \n",
    "\n",
    "import os\n",
    "import openai\n",
    "import sys\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY'] # Provide openAI API key\n",
    "\n",
    "def openai_embeddings(key=openai.api_key):\n",
    "    return OpenAIEmbeddings(openai_api_key=key)\n",
    "embeddings=openai_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688b678e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Vectorspace to store the embedded data\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "def chroma_db(docs,embeddings):\n",
    "    db = Chroma.from_documents(docs, embeddings)\n",
    "    return db\n",
    "\n",
    "db=chroma_db(md_split,embeddings)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038eccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using gpt for send llm calls\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm_name = \"gpt-3.5-turbo\" # Use required model\n",
    "\n",
    "def llm(llm_name=llm_name, temp=0,key=openai.api_key):\n",
    "    llm = ChatOpenAI(model_name=llm_name, temperature=temp,openai_api_key=key)\n",
    "    return llm\n",
    "\n",
    "llm=llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e593723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a retrival chain for extracting from vectorspace and sending calls to llm\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Keep the answer as concise as possible but be as informative as possible. Always say \"Thanks for asking! Feel free to ask anymore Questions\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"],template=template,)\n",
    "\n",
    "def qa_retrival_chain(db, llm):\n",
    "    qa= ConversationalRetrievalChain.from_llm(\n",
    "        llm,\n",
    "        chain_type=\"stuff\", # Can use other methods for larger documents (More expensive due to more llm calls)\n",
    "        retriever=db.as_retriever(),\n",
    "        return_generated_question=True\n",
    "    )\n",
    "    return qa\n",
    "\n",
    "def qa_chain_from_promt(db, llm, promt=QA_CHAIN_PROMPT):\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=db.as_retriever(),\n",
    "        chain_type_kwargs={\"prompt\": promt}\n",
    "    )\n",
    "    return qa_chain\n",
    "\n",
    "qa=qa_retrival_chain(db,llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7f2f6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Chatbot creation with chat history for previous interactions\n",
    "\n",
    "query=input(\"Enter Query \\nUser:\")\n",
    "chat_history = []\n",
    "while(1):\n",
    "    if (query==\"end\" or query==\"\"):\n",
    "        print(\"Chatbot: Session Complete!\")\n",
    "        break\n",
    "    else:\n",
    "        result=qa({\"question\": query,\"chat_history\": chat_history})\n",
    "        chat_history.extend([(query, result[\"answer\"])])\n",
    "        print(\"Chatbot:\"+result['answer']+\"\\n\")\n",
    "        query=input(\"User: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c081447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58be821",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
